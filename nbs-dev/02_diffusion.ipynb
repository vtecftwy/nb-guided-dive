{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b367396",
   "metadata": {},
   "source": [
    "# Imports\n",
    "> Imports all required packages common to all notebooks used in guided dives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41704679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f5b6f7",
   "metadata": {},
   "source": [
    "List of all packages and objects which should be imported and accessible from the guided dive notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5879e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "imported_objects  = [\n",
    "    'Image', 'concat','torch', 'logging', 'Path', 'notebook_login', 'StableDiffusionPipeline', 'plt', \n",
    "    'StableDiffusionImg2ImgPipeline', 'FastDownload'\n",
    "]\n",
    "try:\n",
    "    __all__.extend(imported_objects)\n",
    "except:\n",
    "    __all__ = imported_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6e5bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from PIL import Image\n",
    "from fastcore.all import concat\n",
    "import torch, logging\n",
    "from pathlib import Path\n",
    "from huggingface_hub import notebook_login\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from fastdownload import FastDownload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bd9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def mount_gdrive(path_to_ds=None):\n",
    "\n",
    "    if path_to_ds is None:\n",
    "        dataset = Path('/content/gdrive/MyDrive/img-ds.zip')\n",
    "    else:\n",
    "        dataset = Path(path_to_ds)\n",
    "\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/gdrive')\n",
    "        if not dataset.is_file():\n",
    "            raise ValueError(f\"Dataset cannot be found at <{dataset.absolute()}> \")\n",
    "    except:\n",
    "        print('This notebook should be run on Google Colab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4471367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def config_hugginface_for_colab():\n",
    "    \n",
    "    logging.disable(logging.WARNING)\n",
    "\n",
    "    torch.manual_seed(1)\n",
    "    if not (Path.home()/'.huggingface'/'token').exists(): notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae6b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
